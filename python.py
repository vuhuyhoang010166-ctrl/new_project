# -*- coding: utf-8 -*-
"""
T√™n ·ª©ng d·ª•ng: Tr√¨nh Ph√¢n T√≠ch Ph∆∞∆°ng √Ån Kinh Doanh
T√°c gi·∫£: Gemini AI (v·ªõi vai tr√≤ chuy√™n gia Python/Streamlit)
M√¥ t·∫£: ·ª®ng d·ª•ng Streamlit s·ª≠ d·ª•ng AI ƒë·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu t√†i ch√≠nh t·ª´ file Word,
       t√≠nh to√°n c√°c ch·ªâ s·ªë hi·ªáu qu·∫£ d·ª± √°n (NPV, IRR, PP, DPP) v√† ƒë∆∞a ra ph√¢n t√≠ch.
"""

import streamlit as st
import pandas as pd
import numpy_financial as npf
import google.generativeai as genai
from docx import Document
import json
import io

# --- C·∫•u h√¨nh Trang v√† Ti√™u ƒë·ªÅ ---
st.set_page_config(
    page_title="Tr√¨nh Ph√¢n T√≠ch Ph∆∞∆°ng √Ån Kinh Doanh",
    page_icon="üíº",
    layout="wide"
)

st.title("üíº Tr√¨nh Ph√¢n T√≠ch Ph∆∞∆°ng √Ån Kinh Doanh AI")
st.caption("T·∫£i l√™n ph∆∞∆°ng √°n kinh doanh d∆∞·ªõi d·∫°ng file Word (.docx) ƒë·ªÉ AI ph√¢n t√≠ch v√† ƒë√°nh gi√°.")

# --- KH·ªûI T·∫†O BI·∫æN TR·∫†NG TH√ÅI (SESSION STATE) ---
# R·∫•t quan tr·ªçng ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu gi·ªØa c√°c l·∫ßn ch·∫°y l·∫°i c·ªßa script
if 'project_data' not in st.session_state:
    st.session_state.project_data = None
if 'cash_flow_df' not in st.session_state:
    st.session_state.cash_flow_df = None
if 'metrics' not in st.session_state:
    st.session_state.metrics = None
if 'analysis_requested' not in st.session_state:
    st.session_state.analysis_requested = False


# --- H√ÄM H·ªñ TR·ª¢ ---

def extract_text_from_docx(uploaded_file):
    """ƒê·ªçc v√† tr√≠ch xu·∫•t to√†n b·ªô vƒÉn b·∫£n t·ª´ file .docx."""
    # S·ª≠ d·ª•ng BytesIO ƒë·ªÉ ƒë·ªçc file t·ª´ b·ªô nh·ªõ m√† kh√¥ng c·∫ßn l∆∞u xu·ªëng ƒëƒ©a
    document = Document(io.BytesIO(uploaded_file.read()))
    full_text = [para.text for para in document.paragraphs]
    return '\n'.join(full_text)

def get_project_data_from_ai(text, api_key):
    """
    S·ª≠ d·ª•ng Gemini AI ƒë·ªÉ tr√≠ch xu·∫•t c√°c th√¥ng s·ªë t√†i ch√≠nh t·ª´ vƒÉn b·∫£n.
    Tr·∫£ v·ªÅ m·ªôt dictionary Python.
    """
    try:
        genai.configure(api_key=api_key)
        # *** ƒê√É S·ª¨A: Thay ƒë·ªïi t·ª´ 'gemini-1.5-flash-latest' sang 'gemini-1.5-flash' ***
        model = genai.GenerativeModel('gemini-1.5-flash')

        # Prompt ƒë∆∞·ª£c thi·∫øt k·∫ø k·ªπ l∆∞·ª°ng ƒë·ªÉ y√™u c·∫ßu AI tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng JSON,
        # gi√∫p vi·ªác x·ª≠ l√Ω d·ªØ li·ªáu tr·ªü n√™n ƒë√°ng tin c·∫≠y h∆°n.
        prompt = f"""
        B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch t√†i ch√≠nh. H√£y ƒë·ªçc k·ªπ vƒÉn b·∫£n ph∆∞∆°ng √°n kinh doanh d∆∞·ªõi ƒë√¢y.
        Tr√≠ch xu·∫•t ch√≠nh x√°c c√°c th√¥ng tin sau v√† tr·∫£ v·ªÅ d∆∞·ªõi d·∫°ng m·ªôt ƒë·ªëi t∆∞·ª£ng JSON duy nh·∫•t.
        N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin n√†o, h√£y tr·∫£ v·ªÅ gi√° tr·ªã 0 cho tr∆∞·ªùng ƒë√≥.

        1. "von_dau_tu": T·ªïng v·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu (ƒë∆°n v·ªã: VNƒê).
        2. "dong_doi_du_an": D√≤ng ƒë·ªùi d·ª± √°n (ƒë∆°n v·ªã: nƒÉm).
        3. "doanh_thu_nam": Doanh thu trung b√¨nh h√†ng nƒÉm (ƒë∆°n v·ªã: VNƒê).
        4. "chi_phi_nam": Chi ph√≠ ho·∫°t ƒë·ªông trung b√¨nh h√†ng nƒÉm (kh√¥ng bao g·ªìm v·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu) (ƒë∆°n v·ªã: VNƒê).
        5. "wacc": T·ª∑ l·ªá chi·∫øt kh·∫•u ho·∫∑c chi ph√≠ s·ª≠ d·ª•ng v·ªën b√¨nh qu√¢n (WACC) (ƒë∆°n v·ªã: ph·∫ßn trƒÉm, v√≠ d·ª•: 12.5 cho 12.5%).
        6. "thue_suat": Thu·∫ø su·∫•t thu·∫ø thu nh·∫≠p doanh nghi·ªáp (ƒë∆°n v·ªã: ph·∫ßn trƒÉm, v√≠ d·ª•: 20 cho 20%).

        VƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch:
        ---
        {text}
        ---

        H√£y ƒë·∫£m b·∫£o k·∫øt qu·∫£ ch·ªâ l√† m·ªôt ƒë·ªëi t∆∞·ª£ng JSON h·ª£p l·ªá, kh√¥ng c√≥ b·∫•t k·ª≥ vƒÉn b·∫£n gi·∫£i th√≠ch n√†o kh√°c.
        V√≠ d·ª• ƒë·ªãnh d·∫°ng ƒë·∫ßu ra:
        {{
          "von_dau_tu": 5000000000,
          "dong_doi_du_an": 5,
          "doanh_thu_nam": 3000000000,
          "chi_phi_nam": 1500000000,
          "wacc": 12.5,
          "thue_suat": 20
        }}
        """
        response = model.generate_content(prompt)
        # Lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng c·∫ßn thi·∫øt m√† AI c√≥ th·ªÉ th√™m v√†o
        cleaned_response = response.text.strip().replace('```json', '').replace('```', '')
        return json.loads(cleaned_response)

    except Exception as e:
        st.error(f"L·ªói khi g·ªçi API c·ªßa AI: {e}")
        st.error(f"Ph·∫£n h·ªìi nh·∫≠n ƒë∆∞·ª£c t·ª´ AI: {response.text if 'response' in locals() else 'Kh√¥ng c√≥ ph·∫£n h·ªìi'}")
        return None

@st.cache_data
def calculate_financials(project_data):
    """
    X√¢y d·ª±ng b·∫£ng d√≤ng ti·ªÅn v√† t√≠nh to√°n c√°c ch·ªâ s·ªë t√†i ch√≠nh.
    S·ª≠ d·ª•ng @st.cache_data ƒë·ªÉ kh√¥ng ph·∫£i t√≠nh to√°n l·∫°i n·∫øu ƒë·∫ßu v√†o kh√¥ng ƒë·ªïi.
    """
    try:
        # L·∫•y d·ªØ li·ªáu v√† chuy·ªÉn ƒë·ªïi sang ƒë√∫ng ƒë·ªãnh d·∫°ng
        investment = float(project_data['von_dau_tu'])
        lifespan = int(project_data['dong_doi_du_an'])
        revenue = float(project_data['doanh_thu_nam'])
        costs = float(project_data['chi_phi_nam'])
        wacc = float(project_data['wacc']) / 100.0
        tax_rate = float(project_data['thue_suat']) / 100.0

        # --- X√¢y d·ª±ng b·∫£ng d√≤ng ti·ªÅn ---
        years = list(range(lifespan + 1))
        profit_before_tax = [0] * (lifespan + 1)
        tax = [0] * (lifespan + 1)
        profit_after_tax = [0] * (lifespan + 1)
        net_cash_flow = [0] * (lifespan + 1)

        net_cash_flow[0] = -investment  # D√≤ng ti·ªÅn nƒÉm 0 l√† v·ªën ƒë·∫ßu t∆∞

        for year in range(1, lifespan + 1):
            profit_before_tax[year] = revenue - costs
            tax[year] = profit_before_tax[year] * tax_rate if profit_before_tax[year] > 0 else 0
            profit_after_tax[year] = profit_before_tax[year] - tax[year]
            # Gi·∫£ ƒë·ªãnh ƒë∆°n gi·∫£n: D√≤ng ti·ªÅn thu·∫ßn = L·ª£i nhu·∫≠n sau thu·∫ø
            # (Trong th·ª±c t·∫ø c√≥ th·ªÉ c·ªông l·∫°i kh·∫•u hao)
            net_cash_flow[year] = profit_after_tax[year]

        cash_flow_df = pd.DataFrame({
            "NƒÉm": years,
            "Doanh thu": [0] + [revenue] * lifespan,
            "Chi ph√≠": [0] + [costs] * lifespan,
            "L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø": profit_before_tax,
            "Thu·∫ø TNDN": tax,
            "L·ª£i nhu·∫≠n sau thu·∫ø": profit_after_tax,
            "D√≤ng ti·ªÅn thu·∫ßn (NCF)": net_cash_flow
        })

        # --- T√≠nh to√°n c√°c ch·ªâ s·ªë ---
        # NPV (Gi√° tr·ªã hi·ªán t·∫°i r√≤ng)
        npv = npf.npv(wacc, net_cash_flow)

        # IRR (T·ª∑ su·∫•t ho√†n v·ªën n·ªôi b·ªô)
        try:
            irr = npf.irr(net_cash_flow) * 100
        except:
            irr = "Kh√¥ng th·ªÉ t√≠nh" # X·∫£y ra khi d√≤ng ti·ªÅn kh√¥ng ƒë·ªïi d·∫•u

        # PP (Th·ªùi gian ho√†n v·ªën)
        cumulative_cash_flow = cash_flow_df['D√≤ng ti·ªÅn thu·∫ßn (NCF)'].cumsum()
        try:
            # NƒÉm tr∆∞·ªõc khi ho√†n v·ªën
            last_negative_year = cumulative_cash_flow[cumulative_cash_flow < 0].idxmax()
            # S·ªë ti·ªÅn c·∫ßn b√π ƒë·∫Øp ·ªü nƒÉm ho√†n v·ªën
            recovery_needed = -cumulative_cash_flow.iloc[last_negative_year]
            # D√≤ng ti·ªÅn c·ªßa nƒÉm ho√†n v·ªën
            cash_flow_recovery_year = cash_flow_df['D√≤ng ti·ªÅn thu·∫ßn (NCF)'].iloc[last_negative_year + 1]
            pp = last_negative_year + (recovery_needed / cash_flow_recovery_year)
        except:
            pp = "Kh√¥ng ho√†n v·ªën"

        # DPP (Th·ªùi gian ho√†n v·ªën c√≥ chi·∫øt kh·∫•u)
        cash_flow_df['D√≤ng ti·ªÅn chi·∫øt kh·∫•u'] = [ncf / ((1 + wacc)**year) for year, ncf in enumerate(net_cash_flow)]
        cash_flow_df['D√≤ng ti·ªÅn chi·∫øt kh·∫•u l≈©y k·∫ø'] = cash_flow_df['D√≤ng ti·ªÅn chi·∫øt kh·∫•u'].cumsum()
        try:
            last_negative_year_d = cash_flow_df['D√≤ng ti·ªÅn chi·∫øt kh·∫•u l≈©y k·∫ø'][cash_flow_df['D√≤ng ti·ªÅn chi·∫øt kh·∫•u l≈©y k·∫ø'] < 0].idxmax()
            recovery_needed_d = -cash_flow_df['D√≤ng ti·ªÅn chi·∫øt kh·∫•u l≈©y k·∫ø'].iloc[last_negative_year_d]
            cash_flow_recovery_year_d = cash_flow_df['D√≤ng ti·ªÅn chi·∫øt kh·∫•u'].iloc[last_negative_year_d + 1]
            dpp = last_negative_year_d + (recovery_needed_d / cash_flow_recovery_year_d)
        except:
            dpp = "Kh√¥ng ho√†n v·ªën"

        metrics = {
            "NPV": npv,
            "IRR": irr,
            "PP": pp,
            "DPP": dpp
        }

        return cash_flow_df, metrics
    except (TypeError, ValueError, KeyError) as e:
        st.error(f"D·ªØ li·ªáu ƒë·∫ßu v√†o kh√¥ng h·ª£p l·ªá ƒë·ªÉ t√≠nh to√°n. Vui l√≤ng ki·ªÉm tra l·∫°i th√¥ng tin AI ƒë√£ tr√≠ch xu·∫•t. L·ªói: {e}")
        return None, None

def get_ai_analysis(metrics, api_key):
    """G·ª≠i c√°c ch·ªâ s·ªë ƒë√£ t√≠nh to√°n ƒë·ªÉ AI ƒë∆∞a ra ph√¢n t√≠ch chuy√™n s√¢u."""
    try:
        genai.configure(api_key=api_key)
        # *** ƒê√É S·ª¨A: Thay ƒë·ªïi t·ª´ 'gemini-1.5-flash-latest' sang 'gemini-1.5-flash' ***
        model = genai.GenerativeModel('gemini-1.5-flash')

        prompt = f"""
        V·ªõi vai tr√≤ l√† m·ªôt chuy√™n gia t∆∞ v·∫•n ƒë·∫ßu t∆∞, h√£y ph√¢n t√≠ch c√°c ch·ªâ s·ªë hi·ªáu qu·∫£ d·ª± √°n d∆∞·ªõi ƒë√¢y v√† ƒë∆∞a ra nh·∫≠n ƒë·ªãnh chuy√™n m√¥n.
        Gi·∫£i th√≠ch ng·∫Øn g·ªçn √Ω nghƒ©a c·ªßa t·ª´ng ch·ªâ s·ªë trong b·ªëi c·∫£nh c·ªßa d·ª± √°n n√†y.
        Cu·ªëi c√πng, ƒë∆∞a ra m·ªôt k·∫øt lu·∫≠n t·ªïng quan v·ªÅ t√≠nh kh·∫£ thi c·ªßa d·ª± √°n (v√≠ d·ª•: r·∫•t kh·∫£ thi, c·∫ßn c√¢n nh·∫Øc, r·ªßi ro cao...).

        C√°c ch·ªâ s·ªë c·∫ßn ph√¢n t√≠ch:
        - Gi√° tr·ªã hi·ªán t·∫°i r√≤ng (NPV): {metrics['NPV']:,.0f} VNƒê
        - T·ª∑ su·∫•t ho√†n v·ªën n·ªôi b·ªô (IRR): {f"{metrics['IRR']:.2f}%" if isinstance(metrics['IRR'], float) else metrics['IRR']}
        - Th·ªùi gian ho√†n v·ªën (PP): {f"{metrics['PP']:.2f} nƒÉm" if isinstance(metrics['PP'], float) else metrics['PP']}
        - Th·ªùi gian ho√†n v·ªën c√≥ chi·∫øt kh·∫•u (DPP): {f"{metrics['DPP']:.2f} nƒÉm" if isinstance(metrics['DPP'], float) else metrics['DPP']}

        H√£y tr√¨nh b√†y c√¢u tr·∫£ l·ªùi m·ªôt c√°ch chuy√™n nghi·ªáp, c√≥ c·∫•u tr√∫c r√µ r√†ng v·ªõi c√°c ƒë·ªÅ m·ª•c cho t·ª´ng ph·∫ßn.
        """
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        st.error(f"L·ªói khi g·ªçi API c·ªßa AI ƒë·ªÉ ph√¢n t√≠ch: {e}")
        return "Kh√¥ng th·ªÉ nh·∫≠n ƒë∆∞·ª£c ph√¢n t√≠ch t·ª´ AI."

# --- GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG ---

# C·ªôt b√™n tr√°i cho vi·ªác nh·∫≠p li·ªáu, c·ªôt b√™n ph·∫£i cho API Key
col1, col2 = st.columns([3, 1])

with col1:
    uploaded_file = st.file_uploader(
        "1. T·∫£i l√™n file ph∆∞∆°ng √°n kinh doanh (.docx)",
        type=['docx']
    )

with col2:
    # L·∫•y API Key t·ª´ Streamlit Secrets
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
        st.success("ƒê√£ t√¨m th·∫•y API Key.", icon="üîë")
    except:
        api_key = st.text_input("Ho·∫∑c nh·∫≠p Gemini API Key c·ªßa b·∫°n v√†o ƒë√¢y:", type="password")


if uploaded_file is not None and api_key:
    # --- B∆Ø·ªöC 1: TR√çCH XU·∫§T D·ªÆ LI·ªÜU ---
    st.markdown("---")
    st.subheader("B∆∞·ªõc 1: Tr√≠ch xu·∫•t th√¥ng tin b·∫±ng AI")

    if st.button("L·ªçc d·ªØ li·ªáu t·ª´ file Word", type="primary"):
        with st.spinner("AI ƒëang ƒë·ªçc v√† ph√¢n t√≠ch file... Vui l√≤ng ch·ªù trong gi√¢y l√°t..."):
            # Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ file
            document_text = extract_text_from_docx(uploaded_file)
            # G·ªçi AI ƒë·ªÉ l·∫•y d·ªØ li·ªáu c√≥ c·∫•u tr√∫c
            st.session_state.project_data = get_project_data_from_ai(document_text, api_key)
            # ƒê·∫∑t l·∫°i c√°c k·∫øt qu·∫£ c≈©
            st.session_state.cash_flow_df = None
            st.session_state.metrics = None
            st.session_state.analysis_requested = False


    if st.session_state.project_data:
        st.success("‚úÖ AI ƒë√£ tr√≠ch xu·∫•t th√†nh c√¥ng d·ªØ li·ªáu!")
        with st.expander("Xem d·ªØ li·ªáu AI ƒë√£ l·ªçc", expanded=True):
            # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë√£ tr√≠ch xu·∫•t d∆∞·ªõi d·∫°ng c√°c metric ƒë·ªÉ d·ªÖ nh√¨n h∆°n
            p_data = st.session_state.project_data
            metric_col1, metric_col2, metric_col3 = st.columns(3)
            with metric_col1:
                st.metric(label="V·ªën ƒë·∫ßu t∆∞", value=f"{p_data.get('von_dau_tu', 0):,.0f} VNƒê")
                st.metric(label="Doanh thu/nƒÉm", value=f"{p_data.get('doanh_thu_nam', 0):,.0f} VNƒê")
            with metric_col2:
                st.metric(label="D√≤ng ƒë·ªùi d·ª± √°n", value=f"{p_data.get('dong_doi_du_an', 0)} nƒÉm")
                st.metric(label="Chi ph√≠/nƒÉm", value=f"{p_data.get('chi_phi_nam', 0):,.0f} VNƒê")
            with metric_col3:
                st.metric(label="WACC", value=f"{p_data.get('wacc', 0)} %")
                st.metric(label="Thu·∫ø su·∫•t TNDN", value=f"{p_data.get('thue_suat', 0)} %")

        # --- B∆Ø·ªöC 2 & 3: T√çNH TO√ÅN V√Ä HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
        st.markdown("---")
        # Th·ª±c hi·ªán t√≠nh to√°n ngay sau khi c√≥ d·ªØ li·ªáu
        if st.session_state.cash_flow_df is None and st.session_state.metrics is None:
            with st.spinner("ƒêang x√¢y d·ª±ng b·∫£ng d√≤ng ti·ªÅn v√† t√≠nh to√°n c√°c ch·ªâ s·ªë..."):
                df, metrics_data = calculate_financials(st.session_state.project_data)
                if df is not None and metrics_data is not None:
                    st.session_state.cash_flow_df = df
                    st.session_state.metrics = metrics_data

        if st.session_state.cash_flow_df is not None:
            st.subheader("B∆∞·ªõc 2: B·∫£ng D√≤ng Ti·ªÅn D·ª± √Ån")
            # ƒê·ªãnh d·∫°ng c√°c c·ªôt s·ªë cho d·ªÖ ƒë·ªçc
            st.dataframe(st.session_state.cash_flow_df.style.format({
                'Doanh thu': '{:,.0f}',
                'Chi ph√≠': '{:,.0f}',
                'L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø': '{:,.0f}',
                'Thu·∫ø TNDN': '{:,.0f}',
                'L·ª£i nhu·∫≠n sau thu·∫ø': '{:,.0f}',
                'D√≤ng ti·ªÅn thu·∫ßn (NCF)': '{:,.0f}',
                'D√≤ng ti·ªÅn chi·∫øt kh·∫•u': '{:,.0f}',
                'D√≤ng ti·ªÅn chi·∫øt kh·∫•u l≈©y k·∫ø': '{:,.0f}'
            }), use_container_width=True)

        if st.session_state.metrics is not None:
            st.subheader("B∆∞·ªõc 3: C√°c Ch·ªâ S·ªë ƒê√°nh Gi√° Hi·ªáu Qu·∫£ D·ª± √Ån")
            m = st.session_state.metrics
            indicator_cols = st.columns(4)
            with indicator_cols[0]:
                st.metric(label="Gi√° tr·ªã hi·ªán t·∫°i r√≤ng (NPV)", value=f"{m['NPV']:,.0f} VNƒê")
            with indicator_cols[1]:
                st.metric(label="T·ª∑ su·∫•t ho√†n v·ªën n·ªôi b·ªô (IRR)", value=f"{m['IRR']:.2f} %" if isinstance(m['IRR'], float) else m['IRR'])
            with indicator_cols[2]:
                st.metric(label="Th·ªùi gian ho√†n v·ªën (PP)", value=f"{m['PP']:.2f} nƒÉm" if isinstance(m['PP'], float) else m['PP'])
            with indicator_cols[3]:
                st.metric(label="Th·ªùi gian ho√†n v·ªën c√≥ chi·∫øt kh·∫•u (DPP)", value=f"{m['DPP']:.2f} nƒÉm" if isinstance(m['DPP'], float) else m['DPP'])

            # --- B∆Ø·ªöC 4: PH√ÇN T√çCH T·ª™ AI ---
            st.markdown("---")
            st.subheader("B∆∞·ªõc 4: Y√™u c·∫ßu AI Ph√¢n T√≠ch Chuy√™n S√¢u")
            if st.button("Ph√¢n t√≠ch c√°c ch·ªâ s·ªë hi·ªáu qu·∫£", type="primary"):
                st.session_state.analysis_requested = True

            if st.session_state.analysis_requested:
                with st.spinner("AI ƒëang so·∫°n th·∫£o ph√¢n t√≠ch chuy√™n m√¥n..."):
                    analysis_result = get_ai_analysis(st.session_state.metrics, api_key)
                    st.markdown("#### üìù **Nh·∫≠n ƒë·ªãnh t·ª´ Chuy√™n gia AI**")
                    st.info(analysis_result)
else:
    st.info("Vui l√≤ng t·∫£i l√™n file .docx v√† ƒë·∫£m b·∫£o ƒë√£ cung c·∫•p API Key ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
