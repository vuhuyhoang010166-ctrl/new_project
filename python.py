# -*- coding: utf-8 -*-
"""
T√™n ·ª©ng d·ª•ng: Tr√¨nh Ph√¢n T√≠ch Ph∆∞∆°ng √Ån Kinh Doanh
T√°c gi·∫£: Gemini AI (v·ªõi vai tr√≤ chuy√™n gia Python/Streamlit)
M√¥ t·∫£: ·ª®ng d·ª•ng Streamlit s·ª≠ d·ª•ng AI ƒë·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu t√†i ch√≠nh t·ª´ file Word,
       t√≠nh to√°n c√°c ch·ªâ s·ªë hi·ªáu qu·∫£ d·ª± √°n (NPV, IRR, PP, DPP) v√† ƒë∆∞a ra ph√¢n t√≠ch.
"""

import streamlit as st
import pandas as pd
import numpy_financial as npf
import google.generativeai as genai
from docx import Document
import json
import io

# --- C·∫•u h√¨nh Trang v√† Ti√™u ƒë·ªÅ ---
st.set_page_config(
    page_title="Tr√¨nh Ph√¢n T√≠ch Ph∆∞∆°ng √Ån Kinh Doanh",
    page_icon="üíº",
    layout="wide"
)

st.title("üíº Tr√¨nh Ph√¢n T√≠ch Ph∆∞∆°ng √Ån Kinh Doanh AI")
st.caption("T·∫£i l√™n ph∆∞∆°ng √°n kinh doanh d∆∞·ªõi d·∫°ng file Word (.docx) ƒë·ªÉ AI ph√¢n t√≠ch v√† ƒë√°nh gi√°.")

# --- KH·ªûI T·∫†O BI·∫æN TR·∫†NG TH√ÅI (SESSION STATE) ---
if 'project_data' not in st.session_state:
    st.session_state.project_data = None
if 'cash_flow_df' not in st.session_state:
    st.session_state.cash_flow_df = None
if 'metrics' not in st.session_state:
    st.session_state.metrics = None
if 'analysis_requested' not in st.session_state:
    st.session_state.analysis_requested = False
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- H√ÄM H·ªñ TR·ª¢ ---

def extract_text_from_docx(uploaded_file):
    document = Document(io.BytesIO(uploaded_file.read()))
    full_text = [para.text for para in document.paragraphs]
    return '\n'.join(full_text)

def get_project_data_from_ai(text, api_key):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-flash')
        prompt = f"""
        B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch t√†i ch√≠nh. H√£y ƒë·ªçc k·ªπ vƒÉn b·∫£n ph∆∞∆°ng √°n kinh doanh d∆∞·ªõi ƒë√¢y.
        Tr√≠ch xu·∫•t ch√≠nh x√°c c√°c th√¥ng tin sau v√† tr·∫£ v·ªÅ d∆∞·ªõi d·∫°ng m·ªôt ƒë·ªëi t∆∞·ª£ng JSON duy nh·∫•t.
        N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin n√†o, h√£y tr·∫£ v·ªÅ gi√° tr·ªã 0 cho tr∆∞·ªùng ƒë√≥.

        1. "von_dau_tu": T·ªïng v·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu (ƒë∆°n v·ªã: VNƒê).
        2. "dong_doi_du_an": D√≤ng ƒë·ªùi d·ª± √°n (ƒë∆°n v·ªã: nƒÉm).
        3. "doanh_thu_nam": Doanh thu trung b√¨nh h√†ng nƒÉm (ƒë∆°n v·ªã: VNƒê).
        4. "chi_phi_nam": Chi ph√≠ ho·∫°t ƒë·ªông trung b√¨nh h√†ng nƒÉm (kh√¥ng bao g·ªìm v·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu) (ƒë∆°n v·ªã: VNƒê).
        5. "wacc": T·ª∑ l·ªá chi·∫øt kh·∫•u ho·∫∑c chi ph√≠ s·ª≠ d·ª•ng v·ªën b√¨nh qu√¢n (WACC) (ƒë∆°n v·ªã: ph·∫ßn trƒÉm, v√≠ d·ª•: 12.5 cho 12.5%).
        6. "thue_suat": Thu·∫ø su·∫•t thu·∫ø thu nh·∫≠p doanh nghi·ªáp (ƒë∆°n v·ªã: ph·∫ßn trƒÉm, v√≠ d·ª•: 20 cho 20%).

        VƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch:
        ---
        {text}
        ---

        H√£y ƒë·∫£m b·∫£o k·∫øt qu·∫£ ch·ªâ l√† m·ªôt ƒë·ªëi t∆∞·ª£ng JSON h·ª£p l·ªá, kh√¥ng c√≥ b·∫•t k·ª≥ vƒÉn b·∫£n gi·∫£i th√≠ch n√†o kh√°c.
        V√≠ d·ª• ƒë·ªãnh d·∫°ng ƒë·∫ßu ra:
        {{
          "von_dau_tu": 5000000000,
          "dong_doi_du_an": 5,
          "doanh_thu_nam": 3000000000,
          "chi_phi_nam": 1500000000,
          "wacc": 12.5,
          "thue_suat": 20
        }}
        """
        response = model.generate_content(prompt)
        cleaned_response = response.text.strip().replace('```json', '').replace('```', '')
        return json.loads(cleaned_response)
    except Exception as e:
        st.error(f"L·ªói khi g·ªçi API c·ªßa AI: {e}")
        st.error(f"Ph·∫£n h·ªìi nh·∫≠n ƒë∆∞·ª£c t·ª´ AI: {response.text if 'response' in locals() else 'Kh√¥ng c√≥ ph·∫£n h·ªìi'}")
        return None

@st.cache_data
def calculate_financials(project_data):
    try:
        investment = float(project_data['von_dau_tu'])
        lifespan = int(project_data['dong_doi_du_an'])
        revenue = float(project_data['doanh_thu_nam'])
        costs = float(project_data['chi_phi_nam'])
        wacc = float(project_data['wacc']) / 100.0
        tax_rate = float(project_data['thue_suat']) / 100.0

        years = list(range(lifespan + 1))
        profit_before_tax = [0] * (lifespan + 1)
        tax = [0] * (lifespan + 1)
        profit_after_tax = [0] * (lifespan + 1)
        net_cash_flow = [0] * (lifespan + 1)

        net_cash_flow[0] = -investment
        for year in range(1, lifespan + 1):
            profit_before_tax[year] = revenue - costs
            tax[year] = profit_before_tax[year] * tax_rate if profit_before_tax[year] > 0 else 0
            profit_after_tax[year] = profit_before_tax[year] - tax[year]
            net_cash_flow[year] = profit_after_tax[year]

        cash_flow_df = pd.DataFrame({
            "NƒÉm": years,
            "Doanh thu": [0] + [revenue] * lifespan,
            "Chi ph√≠": [0] + [costs] * lifespan,
            "L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø": profit_before_tax,
            "Thu·∫ø TNDN": tax,
            "L·ª£i nhu·∫≠n sau thu·∫ø": profit_after_tax,
            "D√≤ng ti·ªÅn thu·∫ßn (NCF)": net_cash_flow
        })

        npv = npf.npv(wacc, net_cash_flow)
        try:
            irr = npf.irr(net_cash_flow) * 100
        except:
            irr = "Kh√¥ng th·ªÉ t√≠nh"
        cumulative_cash_flow = cash_flow_df['D√≤ng ti·ªÅn thu·∫ßn (NCF)'].cumsum()
        try:
            last_negative_year = cumulative_cash_flow[cumulative_cash_flow < 0].idxmax()
            recovery_needed = -cumulative_cash_flow.iloc[last_negative_year]
            cash_flow_recovery_year = cash_flow_df['D√≤ng ti·ªÅn thu·∫ßn (NCF)'].iloc[last_negative_year + 1]
            pp = last_negative_year + (recovery_needed / cash_flow_recovery_year)
        except:
            pp = "Kh√¥ng ho√†n v·ªën"

        cash_flow_df['D√≤ng ti·ªÅn chi·∫øt kh·∫•u'] = [ncf / ((1 + wacc)**year) for year, ncf in enumerate(net_cash_flow)]
        cash_flow_df['D√≤ng ti·ªÅn chi·∫øt kh·∫•u l≈©y k·∫ø'] = cash_flow_df['D√≤ng ti·ªÅn chi·∫øt kh·∫•u'].cumsum()
        try:
            last_negative_year_d = cash_flow_df['D√≤ng ti·ªÅn chi·∫øt kh·∫•u l≈©y k·∫ø'][cash_flow_df['D√≤ng ti·ªÅn chi·∫øt kh·∫•u l≈©y k·∫ø'] < 0].idxmax()
            recovery_needed_d = -cash_flow_df['D√≤ng ti·ªÅn chi·∫øt kh·∫•u l≈©y k·∫ø'].iloc[last_negative_year_d]
            cash_flow_recovery_year_d = cash_flow_df['D√≤ng ti·ªÅn chi·∫øt kh·∫•u'].iloc[last_negative_year_d + 1]
            dpp = last_negative_year_d + (recovery_needed_d / cash_flow_recovery_year_d)
        except:
            dpp = "Kh√¥ng ho√†n v·ªën"

        metrics = {
            "NPV": npv,
            "IRR": irr,
            "PP": pp,
            "DPP": dpp
        }

        return cash_flow_df, metrics
    except (TypeError, ValueError, KeyError) as e:
        st.error(f"D·ªØ li·ªáu ƒë·∫ßu v√†o kh√¥ng h·ª£p l·ªá ƒë·ªÉ t√≠nh to√°n. Vui l√≤ng ki·ªÉm tra l·∫°i th√¥ng tin AI ƒë√£ tr√≠ch xu·∫•t. L·ªói: {e}")
        return None, None

def get_ai_analysis(metrics, api_key):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-flash')
        prompt = f"""
        V·ªõi vai tr√≤ l√† m·ªôt chuy√™n gia t∆∞ v·∫•n ƒë·∫ßu t∆∞, h√£y ph√¢n t√≠ch c√°c ch·ªâ s·ªë hi·ªáu qu·∫£ d·ª± √°n d∆∞·ªõi ƒë√¢y v√† ƒë∆∞a ra nh·∫≠n ƒë·ªãnh chuy√™n m√¥n.
        Gi·∫£i th√≠ch ng·∫Øn g·ªçn √Ω nghƒ©a c·ªßa t·ª´ng ch·ªâ s·ªë trong b·ªëi c·∫£nh c·ªßa d·ª± √°n n√†y.
        Cu·ªëi c√πng, ƒë∆∞a ra m·ªôt k·∫øt lu·∫≠n t·ªïng quan v·ªÅ t√≠nh kh·∫£ thi c·ªßa d·ª± √°n (v√≠ d·ª•: r·∫•t kh·∫£ thi, c·∫ßn c√¢n nh·∫Øc, r·ªßi ro cao...).

        C√°c ch·ªâ s·ªë c·∫ßn ph√¢n t√≠ch:
        - Gi√° tr·ªã hi·ªán t·∫°i r√≤ng (NPV): {metrics['NPV']:,.0f} VNƒê
        - T·ª∑ su·∫•t ho√†n v·ªën n·ªôi b·ªô (IRR): {f"{metrics['IRR']:.2f}%" if isinstance(metrics['IRR'], float) else metrics['IRR']}
        - Th·ªùi gian ho√†n v·ªën (PP): {f"{metrics['PP']:.2f} nƒÉm" if isinstance(metrics['PP'], float) else metrics['PP']}
        - Th·ªùi gian ho√†n v·ªën c√≥ chi·∫øt kh·∫•u (DPP): {f"{metrics['DPP']:.2f} nƒÉm" if isinstance(metrics['DPP'], float) else metrics['DPP']}

        H√£y tr√¨nh b√†y c√¢u tr·∫£ l·ªùi m·ªôt c√°ch chuy√™n nghi·ªáp, c√≥ c·∫•u tr√∫c r√µ r√†ng v·ªõi c√°c ƒë·ªÅ m·ª•c cho t·ª´ng ph·∫ßn.
        """
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        st.error(f"L·ªói khi g·ªçi API c·ªßa AI ƒë·ªÉ ph√¢n t√≠ch: {e}")
        return "Kh√¥ng th·ªÉ nh·∫≠n ƒë∆∞·ª£c ph√¢n t√≠ch t·ª´ AI."

# ------ H√ÄM CHAT V·ªöI AI ------
def chat_with_ai(user_message, project_data, metrics, api_key):
    """
    G·ª≠i tin nh·∫Øn chat c·ªßa ng∆∞·ªùi d√πng ƒë·∫øn AI. C√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn, th√¢n thi·ªán.
    N·∫øu ƒë√£ c√≥ d·ªØ li·ªáu d·ª± √°n v√† ch·ªâ s·ªë, s·∫Ω ƒë√≠nh k√®m v√†o prompt cho AI.
    """
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-flash')
        context = ""
        if project_data:
            context += f"C√°c th√¥ng tin v·ªÅ d·ª± √°n: {json.dumps(project_data, ensure_ascii=False)}.\n"
        if metrics:
            context += f"C√°c ch·ªâ s·ªë hi·ªáu qu·∫£ d·ª± √°n: {json.dumps(metrics, ensure_ascii=False)}.\n"
        prompt = f"""
        B·∫°n l√† tr·ª£ l√Ω AI th√¢n thi·ªán, tr·∫£ l·ªùi ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu v√† nhi·ªát t√¨nh cho c√¢u h·ªèi sau v·ªÅ ph∆∞∆°ng √°n kinh doanh ho·∫∑c c√°c ch·ªâ s·ªë t√†i ch√≠nh.
        {context}
        C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {user_message}
        """
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return f"L·ªói khi g·ªçi AI: {e}"

# --- GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG ---

col1, col2 = st.columns([3, 1])
with col1:
    uploaded_file = st.file_uploader(
        "1. T·∫£i l√™n file ph∆∞∆°ng √°n kinh doanh (.docx)",
        type=['docx']
    )
with col2:
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
        st.success("ƒê√£ t√¨m th·∫•y API Key.", icon="üîë")
    except:
        api_key = st.text_input("Ho·∫∑c nh·∫≠p Gemini API Key c·ªßa b·∫°n v√†o ƒë√¢y:", type="password")

if uploaded_file is not None and api_key:
    st.markdown("---")
    st.subheader("B∆∞·ªõc 1: Tr√≠ch xu·∫•t th√¥ng tin b·∫±ng AI")

    if st.button("L·ªçc d·ªØ li·ªáu t·ª´ file Word", type="primary"):
        with st.spinner("AI ƒëang ƒë·ªçc v√† ph√¢n t√≠ch file... Vui l√≤ng ch·ªù trong gi√¢y l√°t..."):
            document_text = extract_text_from_docx(uploaded_file)
            st.session_state.project_data = get_project_data_from_ai(document_text, api_key)
            st.session_state.cash_flow_df = None
            st.session_state.metrics = None
            st.session_state.analysis_requested = False

    if st.session_state.project_data:
        st.success("‚úÖ AI ƒë√£ tr√≠ch xu·∫•t th√†nh c√¥ng d·ªØ li·ªáu!")
        with st.expander("Xem d·ªØ li·ªáu AI ƒë√£ l·ªçc", expanded=True):
            p_data = st.session_state.project_data
            metric_col1, metric_col2, metric_col3 = st.columns(3)
            with metric_col1:
                st.metric(label="V·ªën ƒë·∫ßu t∆∞", value=f"{p_data.get('von_dau_tu', 0):,.0f} VNƒê")
                st.metric(label="Doanh thu/nƒÉm", value=f"{p_data.get('doanh_thu_nam', 0):,.0f} VNƒê")
            with metric_col2:
                st.metric(label="D√≤ng ƒë·ªùi d·ª± √°n", value=f"{p_data.get('dong_doi_du_an', 0)} nƒÉm")
                st.metric(label="Chi ph√≠/nƒÉm", value=f"{p_data.get('chi_phi_nam', 0):,.0f} VNƒê")
            with metric_col3:
                st.metric(label="WACC", value=f"{p_data.get('wacc', 0)} %")
                st.metric(label="Thu·∫ø su·∫•t TNDN", value=f"{p_data.get('thue_suat', 0)} %")

        st.markdown("---")
        if st.session_state.cash_flow_df is None and st.session_state.metrics is None:
            with st.spinner("ƒêang x√¢y d·ª±ng b·∫£ng d√≤ng ti·ªÅn v√† t√≠nh to√°n c√°c ch·ªâ s·ªë..."):
                df, metrics_data = calculate_financials(st.session_state.project_data)
                if df is not None and metrics_data is not None:
                    st.session_state.cash_flow_df = df
                    st.session_state.metrics = metrics_data

        if st.session_state.cash_flow_df is not None:
            st.subheader("B∆∞·ªõc 2: B·∫£ng D√≤ng Ti·ªÅn D·ª± √Ån")
            st.dataframe(st.session_state.cash_flow_df.style.format({
                'Doanh thu': '{:,.0f}',
                'Chi ph√≠': '{:,.0f}',
                'L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø': '{:,.0f}',
                'Thu·∫ø TNDN': '{:,.0f}',
                'L·ª£i nhu·∫≠n sau thu·∫ø': '{:,.0f}',
                'D√≤ng ti·ªÅn thu·∫ßn (NCF)': '{:,.0f}',
                'D√≤ng ti·ªÅn chi·∫øt kh·∫•u': '{:,.0f}',
                'D√≤ng ti·ªÅn chi·∫øt kh·∫•u l≈©y k·∫ø': '{:,.0f}'
            }), use_container_width=True)

        if st.session_state.metrics is not None:
            st.subheader("B∆∞·ªõc 3: C√°c Ch·ªâ S·ªë ƒê√°nh Gi√° Hi·ªáu Qu·∫£ D·ª± √Ån")
            m = st.session_state.metrics
            indicator_cols = st.columns(4)
            with indicator_cols[0]:
                st.metric(label="Gi√° tr·ªã hi·ªán t·∫°i r√≤ng (NPV)", value=f"{m['NPV']:,.0f} VNƒê")
            with indicator_cols[1]:
                st.metric(label="T·ª∑ su·∫•t ho√†n v·ªën n·ªôi b·ªô (IRR)", value=f"{m['IRR']:.2f} %" if isinstance(m['IRR'], float) else m['IRR'])
            with indicator_cols[2]:
                st.metric(label="Th·ªùi gian ho√†n v·ªën (PP)", value=f"{m['PP']:.2f} nƒÉm" if isinstance(m['PP'], float) else m['PP'])
            with indicator_cols[3]:
                st.metric(label="Th·ªùi gian ho√†n v·ªën c√≥ chi·∫øt kh·∫•u (DPP)", value=f"{m['DPP']:.2f} nƒÉm" if isinstance(m['DPP'], float) else m['DPP'])

            st.markdown("---")
            st.subheader("B∆∞·ªõc 4: Y√™u c·∫ßu AI Ph√¢n T√≠ch Chuy√™n S√¢u")
            if st.button("Ph√¢n t√≠ch c√°c ch·ªâ s·ªë hi·ªáu qu·∫£", type="primary"):
                st.session_state.analysis_requested = True

            if st.session_state.analysis_requested:
                with st.spinner("AI ƒëang so·∫°n th·∫£o ph√¢n t√≠ch chuy√™n m√¥n..."):
                    analysis_result = get_ai_analysis(st.session_state.metrics, api_key)
                    st.markdown("#### üìù **Nh·∫≠n ƒë·ªãnh t·ª´ Chuy√™n gia AI**")
                    st.info(analysis_result)

            # --------- B·ªî SUNG CH·ª®C NƒÇNG CHAT V·ªöI AI ----------
            st.markdown("---")
            st.subheader("üí¨ Chat v·ªõi AI v·ªÅ d·ª± √°n n√†y")
            chat_input = st.text_input("Nh·∫≠p c√¢u h·ªèi cho AI (v√≠ d·ª•: 'D·ª± √°n n√†y c√≥ r·ªßi ro g√¨?', 'NPV l√† g√¨?', ...)")

            if chat_input:
                with st.spinner("AI ƒëang tr·∫£ l·ªùi..."):
                    ai_response = chat_with_ai(chat_input, st.session_state.project_data, st.session_state.metrics, api_key)
                    st.session_state.chat_history.append({"user": chat_input, "ai": ai_response})

            # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
            if st.session_state.chat_history:
                for chat in st.session_state.chat_history[::-1]:
                    st.markdown(f"**B·∫°n:** {chat['user']}")
                    st.markdown(f"> **AI:** {chat['ai']}")

else:
    st.info("Vui l√≤ng t·∫£i l√™n file .docx v√† ƒë·∫£m b·∫£o ƒë√£ cung c·∫•p API Key ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
